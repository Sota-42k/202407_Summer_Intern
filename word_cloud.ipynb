{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 環境構築（Environment Setup）"
      ],
      "metadata": {
        "id": "s7a3Zou0opEE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_XCfXfbJsjP"
      },
      "outputs": [],
      "source": [
        "# ライブラリ導入\n",
        "!pip install mecab-python3\n",
        "!pip install unidic\n",
        "!python -m unidic download\n",
        "!apt-get -yq install fonts-ipafont-gothic\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import MeCab\n",
        "from collections import Counter\n",
        "import requests\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "from IPython.display import display, HTML\n",
        "import unidic\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Google Drive マウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 作業ディレクトリの変更\n",
        "os.chdir('/content/drive/MyDrive/User')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データプロセシング（Data Processing）"
      ],
      "metadata": {
        "id": "ehE-WCZNosjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV取得\n",
        "cs_hist_df = pd.read_csv('cs_hist.csv', encoding = 'cp932')\n",
        "incident_mgmt_df = pd.read_csv('incident_mgmt.csv', encoding = 'cp932')\n",
        "\n",
        "# データクレンジング関数の宣言\n",
        "def remove_words(text, word_to_remove):\n",
        "  return text.replace(word_to_remove, '')\n",
        "\n",
        "# データクレンジング実行\n",
        "word_to_remove = '\\n'\n",
        "cs_hist_df_edit = cs_hist_df.applymap(lambda x: remove_words(x, word_to_remove) if isinstance(x, str) else x).fillna('').loc[:, ['問合わせ番号', '件名']]\n",
        "incident_mgmt_df_edit = incident_mgmt_df.applymap(lambda x: remove_words(x, word_to_remove) if isinstance(x, str) else x).fillna('').loc[:, ['問合せ番号']]\n",
        "\n",
        "# 顧客対応からインシデントのみ抽出\n",
        "cs_incident_df = cs_hist_df_edit[cs_hist_df_edit['問合わせ番号'].isin(incident_mgmt_df_edit['問合せ番号'])].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "uYdduC9a_5jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 形態素解析（Morphological Analysis）"
      ],
      "metadata": {
        "id": "-h6MXTk9X-CD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 形態素解析関数の宣言\n",
        "def morpheme(dataframe_input, column_input, index_input):\n",
        "  mecab = MeCab.Tagger()\n",
        "  text = dataframe_input[column_input][index_input]\n",
        "  cell_parse = mecab.parse(text)\n",
        "  lines = cell_parse.splitlines()\n",
        "  # EOS(End Of Sentence)の削除\n",
        "  lines = lines[:-1]\n",
        "\n",
        "  # カラムごとの分離・リスト化\n",
        "  data = []\n",
        "  for line in lines:\n",
        "    surface, feature = line.split('\\t')\n",
        "    feature = [None if f == '*' else f for f in feature.split(',')]\n",
        "    data.append([surface, *feature])\n",
        "  return pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "jZm7RokWQ-UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 形態素解析実行関数の宣言\n",
        "def morpheme_df(mor_df_input):\n",
        "  # 形態素解析の実行及びデータフレーム化\n",
        "  words_df = morpheme(mor_df_input, '件名', 1)\n",
        "  for index, row in mor_df_input.iloc[2:].iterrows():\n",
        "    mor_df = morpheme(mor_df_input, '件名', index)\n",
        "    words_df = pd.concat([words_df, mor_df])\n",
        "\n",
        "  # 表層形・品詞・原形のみ抽出\n",
        "  surface_parts_df = words_df.iloc[:, 0:2].reset_index(drop = True)\n",
        "  original = words_df.iloc[:, 8:9].reset_index(drop = True)\n",
        "  words_df_edit = pd.concat([surface_parts_df, original], axis = 1)\n",
        "\n",
        "  COLUMNS = ['表層形', '品詞', '原形']\n",
        "  words_df_edit.columns = COLUMNS\n",
        "\n",
        "  # 名詞・形容詞・動詞・副詞のみ抽出\n",
        "  words_df_edit = words_df_edit[words_df_edit['品詞'].isin(['名詞', '形容詞', '動詞', '副詞'])]\n",
        "\n",
        "  # 形態素解析結果をリスト化\n",
        "  word_cloud_list = list(words_df_edit['原形'].dropna())\n",
        "\n",
        "  # 漢字のみ抽出\n",
        "  def remove_eng(word):\n",
        "    return re.sub(r'-[a-zA-Z]+', '', word)\n",
        "  kana_re = re.compile(\"[^あ-ゖ]\")\n",
        "  word_cloud_list_edit = [s for s in word_cloud_list if kana_re.match(s)]\n",
        "  word_cloud_list_edit = [remove_eng(t) for t in word_cloud_list_edit]\n",
        "\n",
        "  # 重複要素をカウント\n",
        "  word_counts = Counter(word_cloud_list_edit)\n",
        "  word_counts_df = pd.DataFrame.from_dict(word_counts, orient='index').reset_index()\n",
        "  word_counts_df.columns = ['Word', 'Count']\n",
        "  word_counts_df = word_counts_df.sort_values(by = 'Count', ascending = False).reset_index(drop = True)\n",
        "\n",
        "  return word_counts_df"
      ],
      "metadata": {
        "id": "U0tgsgz0RkB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 形態素解析の実行\n",
        "cs_word_cloud_df = morpheme_df(cs_hist_df_edit)\n",
        "incident_word_cloud_df = morpheme_df(cs_incident_df)"
      ],
      "metadata": {
        "id": "o3QuFSnmSsgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 比率計算関数の宣言\n",
        "def calc_rate(pop_df, samp_df):\n",
        "  rate_df = pd.merge(pop_df, samp_df, on = 'Word', how = 'inner')\n",
        "  rate_df.columns = ['Word', 'CS Count', 'Incident Count']\n",
        "  rate_df['Rate'] = rate_df['Incident Count'] / rate_df['CS Count'] * 100\n",
        "  rate_df['Rate'] = rate_df['Rate'].round(2)\n",
        "  rate_df = rate_df[rate_df['CS Count'] >= 10].sort_values(['Rate', 'CS Count'], ascending = False).reset_index(drop = True)\n",
        "  return rate_df"
      ],
      "metadata": {
        "id": "upYBYUaOqeHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 比率計算関数の実行\n",
        "cs_incident_rate_df = calc_rate(cs_word_cloud_df, incident_word_cloud_df)"
      ],
      "metadata": {
        "id": "8SzMDGE0oik3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ワードクラウド（Word Cloud）"
      ],
      "metadata": {
        "id": "AMlixUarX6eA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ワードクラウド作成関数の宣言\n",
        "def word_cloud(word_cloud_df, freq):\n",
        "  # ワードクラウド用の辞書を作成\n",
        "  word_freq = dict(zip(word_cloud_df['Word'], word_cloud_df[freq]))\n",
        "\n",
        "  # ワードクラウドを作成\n",
        "  wordcloud = WordCloud(\n",
        "    background_color = \"white\",\n",
        "    width = 800,\n",
        "    height = 800,\n",
        "    font_path = '/usr/share/fonts/truetype/fonts-japanese-gothic.ttf',\n",
        "    colormap = 'viridis',\n",
        "    max_words = 50,\n",
        "    ).generate_from_frequencies(word_freq)\n",
        "  return wordcloud"
      ],
      "metadata": {
        "id": "Na1CtZVAL7A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ワードクラウド作成関数の実行\n",
        "word_cloud_cs = word_cloud(cs_word_cloud_df, 'Count')\n",
        "word_cloud_incident = word_cloud(incident_word_cloud_df, 'Count')\n",
        "word_cloud_rate = word_cloud(cs_incident_rate_df, 'Rate')\n",
        "\n",
        "# モデルの並列表示\n",
        "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
        "jp_font = fm.FontProperties(fname = '/usr/share/fonts/truetype/fonts-japanese-gothic.ttf')\n",
        "\n",
        "# 各サブプロットにデータをプロット\n",
        "axs[0].imshow(word_cloud_cs, interpolation = 'bilinear')\n",
        "axs[0].set_title('顧客対応履歴', fontproperties = jp_font)\n",
        "axs[0].axis('off')\n",
        "\n",
        "axs[1].imshow(word_cloud_incident, interpolation = 'bilinear')\n",
        "axs[1].set_title('インシデント', fontproperties = jp_font)\n",
        "axs[1].axis('off')\n",
        "\n",
        "axs[2].imshow(word_cloud_rate, interpolation = 'bilinear')\n",
        "axs[2].set_title('インシデント率', fontproperties = jp_font)\n",
        "axs[2].axis('off')\n",
        "\n",
        "# モデルの表示\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# データフレームの表示\n",
        "def display_side_by_side(*display_dfs):\n",
        "  html_str = ''\n",
        "  for df in display_dfs:\n",
        "    df.index = np.arange(1, len(df)+1)\n",
        "    html_str += df.head(50).to_html() + \"\\t\"\n",
        "  display(HTML('<div style=\"display: flex; justify-content: space-around;\">' + html_str + '</div>'))\n",
        "\n",
        "display_side_by_side(cs_word_cloud_df, incident_word_cloud_df, cs_incident_rate_df)"
      ],
      "metadata": {
        "id": "JC26FEfBS--f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}